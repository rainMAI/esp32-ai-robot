# 提醒语音功能深度修复技术汇总

## 1. 为什么“照抄”参考项目也不行？

这是最令人困惑的地方。实际上，参考项目（14-handheld）的代码逻辑本身存在两个**隐性 Bug**，只是在特定网络环境或服务器环境下没有爆发：

1.  **碎包读取 (Fragmentation)**：参考项目直接将 `http->Read` 的结果塞入编码器。由于 HTTP 是流式传输，每次读取不一定正好满帧（1920字节）。如果读到 1000 字节就强行编码，剩下的 920 字节就是脏数据或静音，导致服务器听到的全是杂音。
2.  **累计延时 (Drift)**：参考项目使用简单的 `vTaskDelay(60)`。但在实际运行中，`HTTP 读取时间 + 编码时间 + 网络开销` 会累加。如果读取耗时 20ms，总周期就变成了 80ms，音频回传语速变成了 **0.75x 慢放**。这会导致服务器 STT 识别严重偏差（把长长的句子识别成“嗯”、“好”）。

## 2. 我们具体修改了哪里？

为了彻底解决上述问题，我们对 `main/application.cc` 进行了以下核心重构：

### A. 引入帧对齐缓冲区 (解决噪音)
我们在数据上传前增加了一个“蓄水池” (`pcm_buffer`)：
- **逻辑**：不管 HTTP 一次读到多少字节，都先存入蓄水池。
- **目标**：只有当蓄水池里的数据攒够了 **1920 字节**（16kHz 下的 60ms 完整帧）时，才触发一次 `PushTaskToEncodeQueue`。
- **效果**：保证了回传音频的连续性和完整性，彻底消除了爆音和“刺刺”的噪音。

### B. 引入上传时钟同步 (解决识别率)
我们抛弃了固定延时，改用基于系统高精度定时器 (`esp_timer`) 的算法：
- **逻辑**：记录回传开始时间。每发出一帧音频（60ms），就计算当前已发出的总毫秒数 vs 系统实际流逝的时间，实时补偿时差。
- **效果**：强制回传语速维持在 **1.0x 标准语速**。服务器现在能像听真人说话一样清晰地“听懂”提醒文案，从而触发正确的 AI 回复。

### C. 优化状态机触发时序 (解决提示音缺失)
- **修改点**：在 `OnClockTimer` 中，将 `SetListeningMode` 挪到了 `Alert()` 之前。
- **原理**：`SetListeningMode` 触发的状态切换会重置解码器（ResetDecoder）。通过调整顺序，我们让“重置”动作在“播音”动作之前彻底完成，防止铃声刚响就被状态切换指令顺手截断。

### D. 响应流程闭环 (解决延迟)
- **修改点**：在上传结束处显式调用 `protocol_->SendStopListening()`。
- **效果**：由于服务器默认会有 VAD（静音检测），如果不主动发结束信号，服务器会傻等 10-40 秒。这个修改让服务器实现“秒回”。

## 3. 修改的文件清单

1.  **`main/application.cc`**:
    - 重构了 `ProcessReminderTts` 的循环读取与上传逻辑。
    - 调整了 `OnClockTimer` 的处理顺序。
2.  **`main/audio/audio_service.cc` & `.h`**:
    - 清理了冗余代码，保持了核心解码/编码队列的纯度。

## 总结
这次修复不是简单的“搬运”，而是针对音频物理特性（帧对齐、采样同步）进行的深度优化。这些优化让你的设备具备了在复杂网络下稳定进行“音频欺骗（回传）”的能力。
